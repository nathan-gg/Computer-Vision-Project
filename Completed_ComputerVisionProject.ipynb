{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathan-gg/Computer-Vision-Project/blob/bear_tracker/Completed_ComputerVisionProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URt4Q-TNmNDj"
      },
      "source": [
        "<center><h1> <b> Object Detection Using YOLO <b> </h1></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIi4bjh7mIJd"
      },
      "source": [
        "This tutorial is designed to provide a comprehensive understanding of how to use YOLO, a state-of-the-art method in computer vision, for detecting objects in images.\n",
        "\n",
        "Object detection and classification is a key technology in many areas, such as automated vehicles, security, and even healthcare.\n",
        "\n",
        "We will begin with the basics of preparing (pre processing) an image dataset, ensuring it is ready for effective model training.We will then explore how YOLO, a type of convolutional neural network, automatically extracts features from images to recognize different objects. Understanding this process is crucial for grasping how YOLO operates.\n",
        "\n",
        "The core of this tutorial is focused on transfer learning using YOLO. We will teach you how to take a pre-trained YOLO model and adapt it to a new dataset. This technique is efficient and powerful, allowing us to harness the strengths of YOLO with less computational effort.\n",
        "\n",
        "By the end of this tutorial, you will have hands-on experience with preparing data, implementing YOLO, and understanding the principles behind it. This tutorial aims to equip students with practical skills and knowledge in one of the most exciting fields in technology."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsmlgXapu5rx"
      },
      "source": [
        "Since its inception, the YOLO family of object detection models has come a long way. YOLOv8 is the most recent addition to this famous anchor-based single-shot family of object detectors. It comes with a bunch of improvements which include state-of-the-art accuracy and speed.  In this article, we will be fine tuning the YOLOv8 object detection model on a real-world pothole detection dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5zL0avFnNaJ"
      },
      "source": [
        "In the previous lecture, you were asked to make your own custom datasets for a project you want to work on. Today we will explore how to finetune YOLO on a certain dataset.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr-j-jCmaHId"
      },
      "source": [
        "Importing required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3_BT3x6HaFLn"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3FGskainy8v"
      },
      "source": [
        "# Dataset Description\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vWhx34xdrPh"
      },
      "source": [
        "Fruit Images for Object Detection\n",
        "\n",
        "available on kaggle => https://www.kaggle.com/datasets/mbkinaci/fruit-images-for-object-detection\n",
        "\n",
        "\n",
        "- 240 images in train folder. 60 images in test folder.\n",
        "\n",
        "- 3 different fruits:\n",
        "\n",
        "    - Apple\n",
        "\n",
        "    - Banana\n",
        "\n",
        "    - Orange\n",
        "\n",
        "The labels are in xml format, which is Extensible markup language.Storing image dataset labels in XML format is quite common. XML provides a clear, hierarchical structure which is ideal for representing the complex data associated with image labels. This includes not just the class of the object, but potentially a wealth of other information like bounding box coordinates, object IDs, and additional metadata.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aQjNM0hDaBb"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "For preprocessing:\n",
        "- We have to convert the dataset into that acceptable by YOLO.\n",
        "  - Heirarchy of folders should be the one accepted by YOLO\n",
        "  - Labels format should be darknet YOLO.\n",
        "  - Labels files should be .txt files\n",
        "- Check and see if there are any missing labels or images. And remove them from dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOsIYgK-Po-8"
      },
      "source": [
        "## Heirarchy of Folders correction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a06DXoMuKt97"
      },
      "source": [
        "Defining paths to train and test folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ3K__xXBGXs"
      },
      "outputs": [],
      "source": [
        "test_dir = 'C:/Videos/BEAR DATA/test_zip/test'\n",
        "train_dir = 'C:/Videos/BEAR DATA/train_zip/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v861_qUkmJW",
        "outputId": "bf0411ca-7e27-4eca-cec4-34ce782b6bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk6QMjZkCo4W"
      },
      "source": [
        "\n",
        "\n",
        "The train and test folders have all the images and labels together.\n",
        "\n",
        "But for YOLO, the directories should be in:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5E1PfIX8Udc"
      },
      "source": [
        "Making directories according to above struture of folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3QylpsoVnMyI",
        "outputId": "4f823132-1a23-4085-9420-42e9f370d46c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2717733706.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# os.makedirs('C:/Videos/BEAR DATA/Final_data')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Videos/BEAR DATA/Final_data/images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Videos/BEAR DATA/Final_data/labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Videos/BEAR DATA/Final_data/images/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "#run it once for making directories\n",
        "\n",
        "# os.makedirs('C:/Videos/BEAR DATA/Final_data')\n",
        "os.makedirs('C:/Videos/BEAR DATA/Final_data/images')\n",
        "os.makedirs('C:/Videos/BEAR DATA/Final_data/labels')\n",
        "os.makedirs('C:/Videos/BEAR DATA/Final_data/images/train')\n",
        "os.makedirs('C:/Videos/BEAR DATA/Final_data/images/val')\n",
        "os.makedirs('C:/Videos/BEAR DATA/Final_data/labels/train')\n",
        "os.makedirs('C:/Videos/BEAR DATA/Final_data/labels/val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn5uUxco8p0S"
      },
      "outputs": [],
      "source": [
        "#set the paths to labels and images directory\n",
        "label_dir= \"C:/Videos/BEAR DATA/Final_data/labels\"\n",
        "image_dir=\"C:/Videos/BEAR DATA/Final_data/images\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSXMa5bJ8RRd"
      },
      "source": [
        "Copy XML files and jpg files from the train folder to the folders created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6hL3GjFNM1eW",
        "outputId": "612b91d0-e0b9-426f-b4bd-964268aa2ddc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#import shutil\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#run it once for copying!\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m.listdir(train_dir):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m file.endswith(\u001b[33m\"\u001b[39m\u001b[33m.xml\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      5\u001b[39m         shutil.copy(os.path.join(train_dir, file), os.path.join(label_dir, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m))\n",
            "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "#import shutil\n",
        "#run it once for copying!\n",
        "for file in os.listdir(train_dir):\n",
        "    if file.endswith(\".xml\"):\n",
        "        shutil.copy(os.path.join(train_dir, file), os.path.join(label_dir, \"train\"))\n",
        "    if file.endswith(\".jpg\"):\n",
        "        image = Image.open(os.path.join(train_dir, file))\n",
        "        image = image.convert(\"RGB\")\n",
        "        new_filename = os.path.splitext(file)[0] + \".jpg\"\n",
        "        image.save(os.path.join(image_dir,\"train\", new_filename), \"JPEG\")\n",
        "        #shutil.copy(os.path.join(train_dir, file), os.path.join(image_dir, \"train\"))\n",
        "\n",
        "\n",
        "#Copy XML files and jpg files from the test folder to the folders created.\n",
        "for file in os.listdir(test_dir):\n",
        "    if file.endswith(\".xml\"):\n",
        "        shutil.copy(os.path.join(test_dir, file), os.path.join(label_dir, \"val\"))\n",
        "    if file.endswith(\".jpg\"):\n",
        "        image = Image.open(os.path.join(test_dir, file))\n",
        "        image = image.convert(\"RGB\")\n",
        "        new_filename = os.path.splitext(file)[0] + \".jpg\"\n",
        "        image.save(os.path.join(image_dir,\"val\", new_filename), \"JPEG\")\n",
        "        #shutil.copy(os.path.join(test_dir, file), os.path.join(image_dir, \"val\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iorGIxGmJrHD"
      },
      "source": [
        "Visualizing somme pictures from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0c-0ZNTJqJ1"
      },
      "outputs": [],
      "source": [
        "#visualize first four sample images from train data\n",
        "for idx, image in enumerate(os.listdir(os.path.join(image_dir, \"train\"))):\n",
        "    img = cv2.imread(os.path.join(image_dir,\"train\", image), 1)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "    if idx == 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u26wLg4-VJlx"
      },
      "source": [
        "## Creating Text files for labels\n",
        "Creating Dataframes from .xml files, from which we will eventually create .txt file for each image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU0hWQ0nVf56"
      },
      "outputs": [],
      "source": [
        "#import glob\n",
        "#import xml.etree.ElementTree as ET\n",
        "\n",
        "df = {'name': [],\n",
        "      'label': [],\n",
        "      'width': [],\n",
        "      'height': [],\n",
        "     'xmin': [],\n",
        "     'ymin': [],\n",
        "     'xmax': [],\n",
        "     'ymax': []}\n",
        "\n",
        "\n",
        "#This is the way to handle xml format files which are in heirarchial form (trees).\n",
        "\n",
        "for idx, anno in enumerate(glob.glob(label_dir+\"/train\" + '/*.xml')):\n",
        "\n",
        "    trees = ET.parse(anno)\n",
        "\n",
        "    print(anno)\n",
        "    root = trees.getroot()\n",
        "    width, height = [], []\n",
        "    for item in root.iter():\n",
        "        print(item)\n",
        "\n",
        "        if item.tag == 'size':\n",
        "            for attr in list(item):\n",
        "                if attr.tag == 'width':\n",
        "                    width =int(round(float(attr.text)))\n",
        "                if attr.tag == 'height':\n",
        "                    height = int(round(float(attr.text)))\n",
        "\n",
        "        if item.tag == 'object':\n",
        "            for attr in list(item):\n",
        "                if 'name' in attr.tag:\n",
        "                    label = attr.text\n",
        "                    df['label'] += [label]\n",
        "                    df['width'] += [width]\n",
        "                    df['height'] += [height]\n",
        "                    df['name'] += [anno.split('/')[-1][0:-4]]\n",
        "\n",
        "                if 'bndbox' in attr.tag:\n",
        "                    for dim in attr:\n",
        "                        if dim.tag == 'xmin':\n",
        "                            xmin = int(round(float(dim.text)))\n",
        "                            df['xmin'] += [xmin]\n",
        "\n",
        "                        if dim.tag == 'ymin':\n",
        "                            ymin = int(round(float(dim.text)))\n",
        "                            df['ymin'] += [ymin]\n",
        "                        if dim.tag == 'xmax':\n",
        "                            xmax = int(round(float(dim.text)))\n",
        "                            df['xmax'] += [xmax]\n",
        "                        if dim.tag == 'ymax':\n",
        "                            ymax = int(round(float(dim.text)))\n",
        "                            df['ymax'] += [ymax]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnV2icMMGArW"
      },
      "source": [
        "Doing the same for validation data labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdYDshWXF-rn"
      },
      "outputs": [],
      "source": [
        "#import glob\n",
        "#import xml.etree.ElementTree as ET\n",
        "\n",
        "df2 = {'name': [],\n",
        "      'label': [],\n",
        "      'width': [],\n",
        "      'height': [],\n",
        "     'xmin': [],\n",
        "     'ymin': [],\n",
        "     'xmax': [],\n",
        "     'ymax': []}\n",
        "\n",
        "\n",
        "#This is the way to handle xml format files which are in heirarchial form (tees).\n",
        "\n",
        "for idx, anno in enumerate(glob.glob(label_dir+\"/val\" + '/*.xml')):\n",
        "\n",
        "    trees = ET.parse(anno)\n",
        "\n",
        "    #print(anno)\n",
        "    root = trees.getroot()\n",
        "    width, height = [], []\n",
        "    for item in root.iter():\n",
        "        #print(item)\n",
        "\n",
        "        if item.tag == 'size':\n",
        "            for attr in list(item):\n",
        "                if attr.tag == 'width':\n",
        "                    width =int(round(float(attr.text)))\n",
        "                if attr.tag == 'height':\n",
        "                    height = int(round(float(attr.text)))\n",
        "\n",
        "        if item.tag == 'object':\n",
        "            for attr in list(item):\n",
        "                if 'name' in attr.tag:\n",
        "                    label = attr.text\n",
        "                    df2['label'] += [label]\n",
        "                    df2['width'] += [width]\n",
        "                    df2['height'] += [height]\n",
        "                    #dataset['name']+=[anno.split('/')[-1][0:-4]]\n",
        "                    df2['name'] += [anno.split('/')[-1][0:-4]]\n",
        "\n",
        "                if 'bndbox' in attr.tag:\n",
        "                    for dim in attr:\n",
        "                        if dim.tag == 'xmin':\n",
        "                            xmin = int(round(float(dim.text)))\n",
        "                            df2['xmin'] += [xmin]\n",
        "\n",
        "                        if dim.tag == 'ymin':\n",
        "                            ymin = int(round(float(dim.text)))\n",
        "                            df2['ymin'] += [ymin]\n",
        "                        if dim.tag == 'xmax':\n",
        "                            xmax = int(round(float(dim.text)))\n",
        "                            df2['xmax'] += [xmax]\n",
        "                        if dim.tag == 'ymax':\n",
        "                            ymax = int(round(float(dim.text)))\n",
        "                            df2['ymax'] += [ymax]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMocPDBXGu4g"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-y6PbuDWN21"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(df)\n",
        "val_df=pd.DataFrame(df2)\n",
        "#df1.head()\n",
        "val_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJM7VYLF7jeV"
      },
      "source": [
        "Visualizing one of the image in train set with the bounding box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvRSViPFjcmY"
      },
      "outputs": [],
      "source": [
        "index= 10 #picture to visualize\n",
        "\n",
        "#import cv2\n",
        "image = cv2.imread(os.path.join(image_dir,\"train\", train_df[\"name\"][index]+\".jpg\"), 1)\n",
        "# Draw rectangle\n",
        "cv2.rectangle(image, (train_df['xmin'][index], train_df['ymin'][index]), (train_df['xmax'][index], train_df['ymax'][index]), (255, 0, 0), 2)\n",
        "# Put label (class_id) near the bbox\n",
        "label = train_df[\"label\"][index]\n",
        "cv2.putText(image, str(label), (train_df['xmin'][index], train_df['ymin'][index]+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
        "# Display image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spGYiG_-7sNk"
      },
      "source": [
        "Checking to see if the above image has bounding boxes around other apples or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_2eKRR1k1uz"
      },
      "outputs": [],
      "source": [
        "train_df[\"name\"][index]\n",
        "filtered_df = train_df[train_df['name'] == train_df[\"name\"][index]]\n",
        "print(filtered_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dGy23ycIgvH"
      },
      "source": [
        "Checking to see the datatypes of all the columns and if there is any null value that needs to be eliminated from the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNnyCtzcWN81"
      },
      "outputs": [],
      "source": [
        "val_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlir2BzGIyVG"
      },
      "source": [
        "What different types of labels are assigned to each sample and checking if they match the provided label/class information, i.e. there are no extra labels due to mistakes in spellings etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3ufSgsLY8r9"
      },
      "outputs": [],
      "source": [
        "print(train_df['label'].unique())\n",
        "print(val_df['label'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KloZ5hlJZBIu"
      },
      "source": [
        "We need to map labels to class_ids required for YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faSi0GJbY-wD"
      },
      "outputs": [],
      "source": [
        "label_map = { 'orange': 0,\n",
        "            'apple': 1,}\n",
        "\n",
        "train_df['class'] = train_df['label'].map(label_map)\n",
        "val_df['class'] = val_df['label'].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AviA4pndHCjt"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiYAHAfffse9"
      },
      "source": [
        "convertig the bounding box format to the one required by YOLO:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFHIs8Irp5H7"
      },
      "outputs": [],
      "source": [
        "# Training data\n",
        "train_df['x_center'] = (train_df['xmin']+train_df['xmax'])/(2*train_df[\"width\"])\n",
        "train_df['y_center'] = (train_df['ymin']+train_df['ymax'])/(2*train_df[\"height\"])\n",
        "train_df['box_width'] = (train_df['xmax']-train_df['xmin'])/ train_df[\"width\"]\n",
        "train_df['box_height'] = (train_df['ymax']-train_df['ymin'])/train_df[\"height\"]\n",
        "\n",
        "#Validation data\n",
        "val_df['x_center'] = (val_df['xmin']+val_df['xmax'])/(2*val_df[\"width\"])\n",
        "val_df['y_center'] = (val_df['ymin']+val_df['ymax'])/(2*val_df[\"height\"])\n",
        "val_df['box_width'] = (val_df['xmax']-val_df['xmin'])/ val_df[\"width\"]\n",
        "val_df['box_height'] = (val_df['ymax']-val_df['ymin'])/val_df[\"height\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8nA4176HM33"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsqNEei6KX8L"
      },
      "source": [
        "Deleting all the sample with Nan values in training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veD12DV6qLjm"
      },
      "outputs": [],
      "source": [
        "#training\n",
        "print(\"before deleting (train data): \" , train_df.shape)\n",
        "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "train_df.dropna(inplace=True)\n",
        "print(\"after deleting(train_data): \" ,train_df.shape)\n",
        "\n",
        "#validation\n",
        "print(\"before deleting (val data): \" , val_df.shape)\n",
        "val_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "val_df.dropna(inplace=True)\n",
        "print(\"after deleting(val data): \" , val_df.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_4hHUpnMrct"
      },
      "source": [
        "converting the dataframe to type *str* (string) to be stored in text files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxUBiq6im9hb"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.astype(str)\n",
        "val_df = val_df.astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4K_JCpzNSYO"
      },
      "source": [
        "If there are more than one bounding boxes in single image, they should be written in one text file. As, you can see in the below example that one image has so many bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AsKjYSFNyx9"
      },
      "outputs": [],
      "source": [
        "filtered_df = train_df[train_df['name'] == train_df[\"name\"][100]]\n",
        "(filtered_df.head(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "mrzcNw-DnXr_",
        "outputId": "93c98e4f-e836-4231-fb3f-6ecd6a433041"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#file_name = [x.split('.')[0] for x in df1[\"name\"]]\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#TRAINING DATA\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#finding all the unique names:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m unique_names= \u001b[43mtrain_df\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m].unique()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#for each unique name, containing multiple bboxes, combine them together.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m unique_names:\n",
            "\u001b[31mNameError\u001b[39m: name 'train_df' is not defined"
          ]
        }
      ],
      "source": [
        "#file_name = [x.split('.')[0] for x in df1[\"name\"]]\n",
        "\n",
        "#TRAINING DATA\n",
        "#finding all the unique names:\n",
        "unique_names= train_df['name'].unique()\n",
        "\n",
        "#for each unique name, containing multiple bboxes, combine them together.\n",
        "for name in unique_names:\n",
        "  data = train_df[train_df.name == name]\n",
        "  box_list = []\n",
        "  for idx in range(len(data)):\n",
        "        row = data.iloc[idx]\n",
        "        box_list.append(row['class']+\" \"+row['x_center']+\" \"+row['y_center']+\" \"+ row['box_width']+\" \"+row['box_height'])\n",
        "\n",
        "#writing on text files\n",
        "  text = \"\\n\".join(box_list)\n",
        "  with open(f'{label_dir}/train/{name}.txt', 'w') as file:\n",
        "            file.write(text)\n",
        "#############################################################################################\n",
        "#VALIDATION DATA\n",
        "#finding all the unique names:\n",
        "unique_names= val_df['name'].unique()\n",
        "\n",
        "#for each unique name, containing multiple bboxes, combine them together.\n",
        "for name in unique_names:\n",
        "  data = val_df[val_df.name == name]\n",
        "  box_list = []\n",
        "  for idx in range(len(data)):\n",
        "        row = data.iloc[idx]\n",
        "        box_list.append(row['class']+\" \"+row['x_center']+\" \"+row['y_center']+\" \"+ row['box_width']+\" \"+row['box_height'])\n",
        "\n",
        "#writing on text files\n",
        "  text = \"\\n\".join(box_list)\n",
        "  with open(f'{label_dir}/val/{name}.txt', 'w') as file:\n",
        "            file.write(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BCBLWEHPxeW"
      },
      "source": [
        "## Checking Missing Files\n",
        "\n",
        "Checking the folders if every image file has a corresponding label file\n",
        "\n",
        "\n",
        "(We will copy the code, we already used in previous turorial after updating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "6h-XIOWvPjt0",
        "outputId": "c379d3ef-b8c7-4a5c-9b0b-ca9977549f00"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'glob' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#The lists of all the images and labels for train and validation set:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_images=\u001b[43mglob\u001b[49m.glob(os.path.join(image_dir, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m*.jpg\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      3\u001b[39m train_labels=glob.glob(os.path.join(label_dir, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m*.txt\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      4\u001b[39m val_images=glob.glob(os.path.join(image_dir, \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m*.jpg\u001b[39m\u001b[33m'\u001b[39m))\n",
            "\u001b[31mNameError\u001b[39m: name 'glob' is not defined"
          ]
        }
      ],
      "source": [
        "#The lists of all the images and labels for train and validation set:\n",
        "train_images=glob.glob(os.path.join(image_dir, \"train\",'*.jpg'))\n",
        "train_labels=glob.glob(os.path.join(label_dir, \"train\",'*.txt'))\n",
        "val_images=glob.glob(os.path.join(image_dir, \"val\",'*.jpg'))\n",
        "val_labels=glob.glob(os.path.join(label_dir, \"val\",'*.txt'))\n",
        "#print(val_labels)\n",
        "\n",
        "# Get the list of filenames without extensions\n",
        "image_files_train = {file.split(\"/\")[-1].split(\".\")[0] for file in train_images}\n",
        "label_files_train = {file.split(\"/\")[-1].split(\".\")[0] for file in train_labels}\n",
        "\n",
        "image_files_val = {file.split(\"/\")[-1].split(\".\")[0] for file in val_images}\n",
        "label_files_val = {file.split(\"/\")[-1].split(\".\")[0] for file in val_labels}\n",
        "#print(image_files_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdD7YqsgTEUn"
      },
      "outputs": [],
      "source": [
        "print(len(image_files_val), \"  =  \", len(label_files_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87QIciWYSEak"
      },
      "outputs": [],
      "source": [
        "# Find extra files in each folder\n",
        "\n",
        "#TRAINING DATA\n",
        "extra_images_train = image_files_train - label_files_train\n",
        "extra_labels_train = label_files_train - image_files_train\n",
        "\n",
        "# Output the results\n",
        "print(f\"Training Extra images (without corresponding labels): {extra_images_train}\")\n",
        "print(f\"Training Extra labels (without corresponding images): {extra_labels_train}\")\n",
        "\n",
        "\n",
        "#VALIDATION DATA\n",
        "extra_images_val = image_files_val - label_files_val\n",
        "extra_labels_val = label_files_val - image_files_val\n",
        "\n",
        "# Output the results\n",
        "print(f\"Validation Extra images (without corresponding labels): {extra_images_val}\")\n",
        "print(f\"Validation Extra labels (without corresponding images): {extra_labels_val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjsTAO4jWkXZ"
      },
      "source": [
        "Make sure that the above info is correct by chceking the data manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSUl92tqX_-g"
      },
      "source": [
        "Now removing from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Pm7yEBx7PhA2",
        "outputId": "f4b803e8-ee48-468a-86cb-2514517da5c0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'extra_images_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mextra_images_train\u001b[49m:\n\u001b[32m      2\u001b[39m      os.remove(os.path.join(image_dir, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, file + \u001b[33m'\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m'\u001b[39m)) \u001b[38;5;66;03m# or '.png' depending on your image format\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m extra_images_val:\n",
            "\u001b[31mNameError\u001b[39m: name 'extra_images_train' is not defined"
          ]
        }
      ],
      "source": [
        "for file in extra_images_train:\n",
        "     os.remove(os.path.join(image_dir, \"train\", file + '.jpg')) # or '.png' depending on your image format\n",
        "\n",
        "for file in extra_images_val:\n",
        "     os.remove(os.path.join(image_dir, \"val\", file + '.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xft3EARSYxiC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw43R3WXYx8h"
      },
      "source": [
        "Now run the above cells again to find if all the missing data is deleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN2zwv_bregY"
      },
      "source": [
        "# Custom object detection using YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KATk9OckmMW4"
      },
      "source": [
        "First install and import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6umDhwXHfHlt",
        "outputId": "8ab9abdf-e212-41e0-cab8-3f8d551889a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.223 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 39.1/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kGO4mlYbrrKY"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwuL7tp_c59K"
      },
      "source": [
        "## Training YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_ftYI9Urupw"
      },
      "source": [
        "We are going to select small pretrained (on COCO dataset) model of YOLOv8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-Tq8dfKrtgW"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolo11n.pt') # pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('/content/drive/MyDrive/IAT360/last.pt')"
      ],
      "metadata": {
        "id": "y-27lm_Ydn01"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FqiHfw3r7YW"
      },
      "source": [
        "The detailed architecture of the model can be seen from:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhzvhCX6sBMW",
        "outputId": "d5f7ac10-fa84-4348-c537-77c5184b89a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YOLO(\n",
              "  (model): DetectionModel(\n",
              "    (model): Sequential(\n",
              "      (0): Conv(\n",
              "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (2): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(8, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): Conv(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (4): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): Conv(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (6): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): Conv(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (8): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): SPPF(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (10): C2PSA(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): Sequential(\n",
              "          (0): PSABlock(\n",
              "            (attn): Attention(\n",
              "              (qkv): Conv(\n",
              "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "              (proj): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "              (pe): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "            )\n",
              "            (ffn): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (12): Concat()\n",
              "      (13): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (15): Concat()\n",
              "      (16): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (17): Conv(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (18): Concat()\n",
              "      (19): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (20): Conv(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (21): Concat()\n",
              "      (22): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (23): Detect(\n",
              "        (cv2): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (cv3): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Sequential(\n",
              "            (0): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (dfl): DFL(\n",
              "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoVO93uwvkz8",
        "outputId": "244f2b45-38f9-4c45-f38d-c0f4c006759d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile config.yaml\n",
        "path: /content/drive/MyDrive/IAT360/BEAR DATA/Final_data\n",
        "train: /content/drive/MyDrive/IAT360/BEAR DATA/Final_data/images/train\n",
        "#test: (test dataset folder path)\n",
        "val: /content/drive/MyDrive/IAT360/BEAR DATA/Final_data/images/val\n",
        "\n",
        "# Classes\n",
        "nc: 2 # replace based on your dataset's number of classes\n",
        "\n",
        "# Class names\n",
        "# replace all class names with your own classes' names\n",
        "names:\n",
        "  0: BEAR\n",
        "  1: NON_BEAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igg-4OKyed29"
      },
      "source": [
        "EmXis path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR4Fhjy5rghb",
        "outputId": "9c641f17-1581-4789-daa9-bfc0ede2e20d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/BEAR DATA-20251026T160105Z-1-001.zip\n",
            "replace /content/data/BEAR DATA/Final_data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip \"/content/drive/MyDrive/BEAR DATA-20251026T160105Z-1-001.zip\" -d /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zfhXgYLtP6l",
        "outputId": "46f4ca24-8528-45c1-e32a-a8bd91b02025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile config.yaml\n",
        "path: /content/data/BEAR DATA/Final_data\n",
        "train: /content/data/BEAR DATA/Final_data/images/train\n",
        "#test: (test dataset folder path)\n",
        "val: /content/data/BEAR DATA/Final_data/images/val\n",
        "\n",
        "# Classes\n",
        "nc: 2 # replace based on your dataset's number of classes\n",
        "\n",
        "# Class names\n",
        "# replace all class names with your own classes' names\n",
        "names:\n",
        "  0: BEAR\n",
        "  1: NON_BEAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAWGrHwsOc8y"
      },
      "source": [
        "Please look at [Yolo train Docs](https://docs.ultralytics.com/modes/train/#train-settings) for hyperparameters for model tuning and configuration, e.g. lr0, imgsz, model etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdZTwxz9Puzp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaQGxW5ZvczW",
        "outputId": "3db57eb1-29b5-4b45-da55-b1429dc513e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.223 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/IAT360/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 26.0MB/s 0.0s\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 95.7MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 1.3Â±0.7 ms, read: 0.2Â±0.1 MB/s, size: 60.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/IAT360/BEAR DATA/Final_data/labels/train.cache... 11365 images, 363 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11365/11365 9.9Mit/s 0.0s\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 96, len(boxes) = 13524. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.1 ms, read: 0.2Â±0.0 MB/s, size: 63.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/IAT360/BEAR DATA/Final_data/labels/val.cache... 744 images, 1 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 744/744 949.4Kit/s 0.0s\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 34, len(boxes) = 999. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0005' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/10      1.24G     0.8436     0.7306      1.246          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1421/1421 0.4it/s 53:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 47/47 2.8it/s 16.6s\n",
            "                   all        744        999      0.829      0.751      0.836      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/10      1.44G     0.9443     0.8898      1.328          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1421/1421 5.5it/s 4:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 47/47 6.6it/s 7.2s\n",
            "                   all        744        999      0.862      0.796       0.88      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/10      1.46G     0.9742     0.9248      1.351          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1421/1421 5.6it/s 4:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 47/47 7.0it/s 6.7s\n",
            "                   all        744        999      0.826      0.795      0.863      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/10      1.46G     0.9522     0.9004      1.342          7        640: 95% â”â”â”â”â”â”â”â”â”â”â”â”€ 1350/1421 5.8it/s 4:02<12.1s"
          ]
        }
      ],
      "source": [
        "model.train(data=\"config.yaml\",epochs=10,patience=5,batch=8, lr0=0.0005,imgsz=640)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r train3.zip /content/runs/detect/train3\n",
        "from google.colab import files\n",
        "files.download(\"train3.zip\")"
      ],
      "metadata": {
        "id": "73o3j_J9bccM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmaNQHDFMJqO"
      },
      "source": [
        "## Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMKiGtztSXwD"
      },
      "source": [
        "[This](https://docs.ultralytics.com/guides/yolo-performance-metrics/) is a very good detailed explanation of different perfromance metrics in YOLO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YM6qU3aRvJe"
      },
      "source": [
        "**Choosing the Right Metrics**\n",
        "\n",
        "Choosing the right metrics to evaluate often depends on the specific application.\n",
        "\n",
        "- mAP: Suitable for a broad assessment of model performance.\n",
        "\n",
        "- IoU: Essential when precise object location is crucial.\n",
        "\n",
        "- Precision: Important when minimizing false detections is a priority.\n",
        "\n",
        "- Recall: Vital when it's important to detect every instance of an object.\n",
        "\n",
        "- F1 Score: Useful when a balance between precision and recall is needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "lK2t5a4-tHnC",
        "outputId": "92da22c0-7b89-469d-db4b-21d77a91f544"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-367423472.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# no arguments needed, dataset and settings remembered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m    \u001b[0;31m# map50-95\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap50\u001b[0m  \u001b[0;31m# map50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap75\u001b[0m  \u001b[0;31m# map75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaps\u001b[0m   \u001b[0;31m# a list contains map50-95 of each category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
        "metrics.box.map    # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps   # a list contains map50-95 of each category\n",
        "metrics.box.mp    # P\n",
        "metrics.box.mr    # R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nksC9hxMV3W"
      },
      "source": [
        "Showing confusion matrix, that is already stored in detect/train folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-IpKKbEMIZ0"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "\n",
        "Image.open('/content/runs/detect/train/confusion_matrix_normalized.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F0uTMKbMQXw"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1DiEK1fcziv"
      },
      "source": [
        "##Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3T_Ahl2avFK"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolo11m.pt' )  # load a custom model\n",
        "\n",
        "# Predict with the model with any image from internet?\n",
        "results = model('https://www.freshpoint.com/wp-content/uploads/2019/08/freshpoint-produce-101-apples-bananas.jpg', save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AsWQ6SCntIR"
      },
      "outputs": [],
      "source": [
        "# SHOW THE IMAGE STORED\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "\n",
        "Image.open('/content/runs/detect/predict/freshpoint-produce-101-apples-bananas.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhHilCtCp6xy"
      },
      "source": [
        "# [IGNORE] Bear Detection CV Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUp8TikQqhN9"
      },
      "source": [
        "Importing required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taYOuz4NqhN-"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX0BPYnw-YoA"
      },
      "source": [
        "Link to Original Dataset:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Link to Combined Dataset with our added images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOPpVFeYrDI_"
      },
      "source": [
        "Defining paths to train and test folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyTk9ReCrDI_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTNw2blibywv"
      },
      "source": [
        "EmXi's Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quRolA28bxBG"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#run it once for making directories\n",
        "\n",
        "#os.makedirs('/content/drive/MyDrive/IAT360/BEAR DATA/Final_Data')\n",
        "os.makedirs('/content/drive/MyDrive/IAT360/BEAR DATA/Final_Data/images')\n",
        "os.makedirs('/content/drive/MyDrive/IAT360/BEAR DATA/Final_Data/labels')\n",
        "os.makedirs('/content/drive/MyDrive/IAT360/BEAR DATA/Final_Data/images/train')\n",
        "os.makedirs('/content/drive/MyDrive/IAT360/BEAR DATA/Final_Data/images/valid')\n",
        "os.makedirs('/content/drive/MyDrive/IAT360/BEAR DATA/Final_Data/labels/train')\n",
        "os.makedirs('/content/drive/MyDrive/IAT360/BEAR DATA/Final_Data/labels/valid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2tpRXRpdiAf"
      },
      "source": [
        "EmXi's Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arJO7CQNdgB3"
      },
      "outputs": [],
      "source": [
        "#set the paths to labels and images directory\n",
        "label_dir= \"/content/drive/MyDrive/IAT360/BEAR DATA/Final_Data/labels\"\n",
        "image_dir=\"/content/drive/MyDrive/IAT360/BEAR DATA/Final_Data/images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGSc-Q2srXMr"
      },
      "outputs": [],
      "source": [
        "#visualize first four sample images from train data\n",
        "for idx, image in enumerate(os.listdir(os.path.join(image_dir, \"train\"))):\n",
        "    img = cv2.imread(os.path.join(image_dir,\"train\", image), 1)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "    if idx == 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VZA-b0XgVDL"
      },
      "source": [
        "## Checking Missing Files\n",
        "\n",
        "Checking the folders if every image file has a corresponding label file\n",
        "\n",
        "\n",
        "(We will copy the code, we already used in previous turorial after updating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7m5I6iRgUhw"
      },
      "outputs": [],
      "source": [
        "#The lists of all the images and labels for train and validation set:\n",
        "train_images=glob.glob(os.path.join(image_dir, \"train\",'*.jpg'))\n",
        "print(train_images)\n",
        "train_labels=glob.glob(os.path.join(label_dir, \"train\",'*.txt'))\n",
        "val_images=glob.glob(os.path.join(image_dir, \"valid\",'*.jpg'))\n",
        "val_labels=glob.glob(os.path.join(label_dir, \"valid\",'*.txt'))\n",
        "#print(val_labels)\n",
        "\n",
        "# Get the list of filenames without extensions\n",
        "image_files_train = {file.split(\"/\")[-1].split(\".\")[0] for file in train_images}\n",
        "label_files_train = {file.split(\"/\")[-1].split(\".\")[0] for file in train_labels}\n",
        "\n",
        "image_files_val = {file.split(\"/\")[-1].split(\".\")[0] for file in val_images}\n",
        "label_files_val = {file.split(\"/\")[-1].split(\".\")[0] for file in val_labels}\n",
        "#print(image_files_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cT4RmJUMgfcG"
      },
      "outputs": [],
      "source": [
        "print(len(image_files_val), \"  =  \", len(label_files_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikRPfeT3gkOb"
      },
      "outputs": [],
      "source": [
        "# Find extra files in each folder\n",
        "\n",
        "#TRAINING DATA\n",
        "extra_images_train = image_files_train - label_files_train\n",
        "extra_labels_train = label_files_train - image_files_train\n",
        "\n",
        "# Output the results\n",
        "print(f\"Training Extra images (without corresponding labels): {extra_images_train}\")\n",
        "print(f\"Training Extra labels (without corresponding images): {extra_labels_train}\")\n",
        "\n",
        "\n",
        "#VALIDATION DATA\n",
        "extra_images_val = image_files_val - label_files_val\n",
        "extra_labels_val = label_files_val - image_files_val\n",
        "\n",
        "# Output the results\n",
        "print(f\"Validation Extra images (without corresponding labels): {extra_images_val}\")\n",
        "print(f\"Validation Extra labels (without corresponding images): {extra_labels_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrkI3kWjgqm_"
      },
      "outputs": [],
      "source": [
        "for file in extra_images_train:\n",
        "     os.remove(os.path.join(image_dir, \"train\", file + '.jpg')) # or '.png' depending on your image format\n",
        "     os.remove(os.path.join(image_dir, \"train\", file + '.png'))\n",
        "\n",
        "for file in extra_images_val:\n",
        "     os.remove(os.path.join(image_dir, \"val\", file + '.jpg'))\n",
        "     os.remove(os.path.join(image_dir, \"val\", file + '.png'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7aQjNM0hDaBb",
        "jhHilCtCp6xy"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}